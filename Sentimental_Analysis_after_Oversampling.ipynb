{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentimental_Analysis_after_Oversampling.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVzhZ4scMYrr"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Yle8Zh5vDrm"
      },
      "source": [
        "### **Problem Statement**\n",
        "\n",
        "Dataset containing several tweets with positive and negative sentiment associated with it.\n",
        "\n",
        "Cyber bullying and hate speech has been a menace for quite a long time,So our objective for this task is to detect speeches tweets associated with negative sentiments.From this dataset we classify a tweet as hate speech if it has racist or sexist tweets associated with it.\n",
        "\n",
        "So our task here is to classify racist and sexist tweets from other tweets and filter them out."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wz__ehGMZaf"
      },
      "source": [
        "url = 'https://raw.githubusercontent.com/AmbujaBudakoti27/Sentiment-Analysis/main/twitter_training_dataset.csv'\n",
        "df = pd.read_csv(url, names=[\"id\", \"label\", \"tweet\"])"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "SsqcZi8bMcqn",
        "outputId": "35141b95-46f0-4480-ef26-01ba5bb724eb"
      },
      "source": [
        "df.head(5)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>id</td>\n",
              "      <td>label</td>\n",
              "      <td>tweet</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>@user when a father is dysfunctional and is s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>bihday your majesty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>#model   i love u take with u all the time in ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  label                                              tweet\n",
              "0  id  label                                              tweet\n",
              "1   1      0   @user when a father is dysfunctional and is s...\n",
              "2   2      0  @user @user thanks for #lyft credit i can't us...\n",
              "3   3      0                                bihday your majesty\n",
              "4   4      0  #model   i love u take with u all the time in ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgljpULHvJzt"
      },
      "source": [
        "### **Dataset Description**\n",
        "\n",
        "The data is in csv format.\n",
        "In computing, a comma-separated values (CSV) file stores tabular data (numbers and text) in plain text.\n",
        "Each line of the file is a data record. Each record consists of one or more fields, separated by commas.\n",
        "\n",
        "Formally, given a training sample of tweets and labels, where label ‘1’ denotes the tweet is racist/sexist and label ‘0’ denotes the tweet is not racist/sexist,our objective is to predict the labels on the given test dataset.\n",
        "\n",
        "### Attribute Information\n",
        "\n",
        "\n",
        "*   id : The id associated with the tweets in the given dataset\n",
        "*   tweets : The tweets collected from various sources and having either postive or negative sentiments\n",
        "*   label : A tweet with label '0' is of positive sentiment while a tweet with label '1' is of negative sentiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mULN9Qg5OUyZ"
      },
      "source": [
        "df.drop('id',axis='columns',inplace=True)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TgThvmNYMeVw",
        "outputId": "8d195a9b-83cd-425b-96f7-8bf5f1a4cfca"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(31963, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFlaQgqJMgtL",
        "outputId": "a7d81d0e-2807-47e9-b567-a14dbf0c69e2"
      },
      "source": [
        "df['label'].value_counts()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        29720\n",
              "1         2242\n",
              "label        1\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVJO6yzuPGyL"
      },
      "source": [
        "**We see here that the data is imbalanced.**\n",
        "\n",
        "### **Imbalanced Learning**\n",
        "\n",
        "\n",
        "\"The class imbalance problem typically occurs when, in a classification problem, there are many more instances of some classes than others. In such cases, standard classifiers tend to be overwhelmed by the large classes and ignore the small ones.\" https://www3.nd.edu/~dial/publications/chawla2004editorial.pdf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bETLMJeNP79-",
        "outputId": "d1648b6d-5bc8-4612-8d57-9a3ea161f498"
      },
      "source": [
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "ps = PorterStemmer()\n",
        "\n",
        "for i in range(0, len(df)):\n",
        "  m = re.sub('[^a-zA-Z]', ' ', df[\"tweet\"][i])\n",
        "  m = re.sub('user', '', m)\n",
        "  m = m.lower()\n",
        "  m = m.split()\n",
        "  m = [ps.stem(word) for word in m if not word in stopwords.words('english')]\n",
        "  m =' '.join(m)\n",
        "  df[\"tweet\"][i] = m"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4pxWMlaIorP",
        "outputId": "c31291f0-b34a-4cf0-e0ae-fefa59f1bc26"
      },
      "source": [
        "# Class count\n",
        "df['label'].value_counts()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        29720\n",
              "1         2242\n",
              "label        1\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SO3wDNYOJfIM"
      },
      "source": [
        "count_pos = 29720\n",
        "count_neg = 2242"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BstbY4y_NPvL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5c5cbb5-0ef5-4365-ed66-cdedbe5c02a6"
      },
      "source": [
        "df_pos = df[df['label'] == '0']\n",
        "df_neg = df[df['label'] == '1']\n",
        "df_pos.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(29720, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSkjvSRjiqi8"
      },
      "source": [
        "## **Mitigating Skewdness of Data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_Otrun6itE8"
      },
      "source": [
        "Some of the techniques that can be used to deal with this are:\n",
        "1. Undersampling\n",
        "2. Oversampling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UAQEtRL9l1JH"
      },
      "source": [
        "Within imbalanced-learn, there are different techniques you can use for oversampling. I will use below two.\n",
        "\n",
        "*  RandomOverSampler\n",
        "*   SMOTE (Synthetic Minority Over-Sampling Technique)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVqsc1-ljyp9"
      },
      "source": [
        "### **RandomOverSampler**\n",
        "Random over-sampling is simply a process of repeating some samples of the minority class and balance the number of samples between classes in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HFOnxKaJrCw"
      },
      "source": [
        "# Oversample 1-class and concat the DataFrames of both classes\n",
        "df_neg_over = df_neg.sample(count_pos, replace=True)\n",
        "df_over = pd.concat([df_pos, df_neg_over], axis=0)\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aa8ErmLjKCed",
        "outputId": "1f3f928d-2367-4be3-80b6-5399305e48b6"
      },
      "source": [
        "df_neg_over.shape, df_over.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((29720, 2), (59440, 2))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "id": "FAkqPSV8L782",
        "outputId": "aa80e888-3786-4852-a720-2381d46e7d2d"
      },
      "source": [
        "df_over"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>father dysfunct selfish drag kid dysfunct run</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>thank lyft credit use caus offer wheelchair va...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>bihday majesti</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>model love u take u time ur</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>factsguid societi motiv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24603</th>\n",
              "      <td>1</td>\n",
              "      <td>michel obama ape heel case begin donaldtrump a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22919</th>\n",
              "      <td>1</td>\n",
              "      <td>think told dictionari</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16574</th>\n",
              "      <td>1</td>\n",
              "      <td>hispan amp feel like stomp listen retweet bori...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31692</th>\n",
              "      <td>1</td>\n",
              "      <td>way facebook repoingsystem fail communitystand...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24193</th>\n",
              "      <td>1</td>\n",
              "      <td>let newyear america chop obes knock amp prejud...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>59440 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      label                                              tweet\n",
              "1         0      father dysfunct selfish drag kid dysfunct run\n",
              "2         0  thank lyft credit use caus offer wheelchair va...\n",
              "3         0                                     bihday majesti\n",
              "4         0                        model love u take u time ur\n",
              "5         0                            factsguid societi motiv\n",
              "...     ...                                                ...\n",
              "24603     1  michel obama ape heel case begin donaldtrump a...\n",
              "22919     1                              think told dictionari\n",
              "16574     1  hispan amp feel like stomp listen retweet bori...\n",
              "31692     1  way facebook repoingsystem fail communitystand...\n",
              "24193     1  let newyear america chop obes knock amp prejud...\n",
              "\n",
              "[59440 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzbEeEFRlEwX"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "cv = CountVectorizer(max_features = 5000)\n",
        "X_r = cv.fit_transform(df_over['tweet']).toarray()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHjl10cDlgfK",
        "outputId": "8a1ed0b8-b7f1-48fc-80d6-e65cfde32688"
      },
      "source": [
        "X_r.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(59440, 5000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1TGR8kcMQ4l",
        "outputId": "13eacfa9-04d2-481c-8510-e63f495e3519"
      },
      "source": [
        "y_r = pd.get_dummies(df_over['label'])\n",
        "y_r = y_r.iloc[:,1].values\n",
        "y_r"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 1, 1, 1], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgCfn1Kglk3g"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_r, y_r, test_size=0.2, random_state=0,  stratify=y_r)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmhW9H-Bk_3_"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "sentiment_detect_model_v1 = MultinomialNB().fit(X_train, y_train)\n",
        "y_pred = sentiment_detect_model_v1.predict(X_test)\n",
        "\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
        "accuracy_v1 = accuracy_score(y_test, y_pred)\n",
        "f1_v1 = f1_score(y_test, y_pred)\n",
        "conf_v1 = confusion_matrix(y_test, y_pred)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRi0Qmhmko8r",
        "outputId": "f1880115-efed-4a4e-9336-0537de006e08"
      },
      "source": [
        "accuracy_v1, f1_v1"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9310228802153432, 0.931904999169573)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-S-z95A_0RB5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd7beab4-bbaa-4492-f34f-611df4d2e2bb"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "classificationr=classification_report(y_test, y_pred)\n",
        "print(classificationr)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.92      0.93      5944\n",
            "           1       0.92      0.94      0.93      5944\n",
            "\n",
            "    accuracy                           0.93     11888\n",
            "   macro avg       0.93      0.93      0.93     11888\n",
            "weighted avg       0.93      0.93      0.93     11888\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7puOUVffTOGO"
      },
      "source": [
        "def pred(text):\n",
        "  m = re.sub('[^a-zA-Z]', ' ', text)\n",
        "  m = re.sub('user', '', m)\n",
        "  m = m.lower()\n",
        "  m = m.split()\n",
        "  m = [ps.stem(word) for word in m if not word in stopwords.words('english')]\n",
        "  m =' '.join(m)\n",
        "  k=[]\n",
        "  k.append(m)\n",
        "  x = cv.transform(k).toarray()\n",
        "  y_pred = sentiment_detect_model_v1.predict(x)\n",
        "  if y_pred[0]==0:\n",
        "    print(\"Positive\")\n",
        "  else:\n",
        "    print(\"Negative\")"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eD7rFa5TUX-x",
        "outputId": "a15cd3a9-e5e6-4a67-93cc-0a605e1ea533"
      },
      "source": [
        "text = \"Die in hell\"\n",
        "pred(text)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Negative\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYlrADNPVkNW",
        "outputId": "2318243b-6bbd-471a-f71b-9021a6f4c112"
      },
      "source": [
        "text = \"The world is a beautiful place\"\n",
        "pred(text)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Positive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1S2sV1_gqKxS"
      },
      "source": [
        "### **SMOTE (Synthetic Minority Over-Sampling Technique)**\n",
        "\n",
        "SMOTE is an over-sampling approach in which the minority class is over-sampled by creating “synthetic” examples rather than by over-sampling with replacement.\n",
        "\n",
        "According to the original research paper \"SMOTE: Synthetic Minority Over-sampling Technique\" (Chawla et al., 2002), \"synthetic samples are generated in the following way: Take the difference between the feature vector (sample) under consideration and its nearest neighbour. Multiply this difference by a random number between 0 and 1, and add it to the feature vector under consideration. This causes the selection of a random point along the line segment between two specific features. This approach effectively forces the decision region of the minority class to become more general.\" What this means is that when SMOTE creates a new synthetic data, it will choose one data to copy, and look at its k nearest neighbours. Then, on feature space, it will create random values in feature space that is between the original sample and its neighbours."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QN-KlQpVmXpd",
        "outputId": "3ad91117-8127-483e-d8ec-d44e9bb2a34e"
      },
      "source": [
        "y = pd.get_dummies(df['label'])\n",
        "y = y.iloc[:,1].values\n",
        "y"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 0, 1, 0], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUcVrX0fml_b"
      },
      "source": [
        "X = cv.fit_transform(df['tweet']).toarray()"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "moZenlZpk9O1",
        "outputId": "e5b27df1-6e99-490e-a343-d250b12d2238"
      },
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "smote = SMOTE(sampling_strategy='minority')\n",
        "X_sm, y_sm = smote.fit_sample(X, y)\n",
        "\n",
        "y_sm.shape"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(59442,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2O4RKC-4nNNN"
      },
      "source": [
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(X_sm, y_sm, test_size=0.2, random_state=15, stratify=y_sm)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rW8grI5nUE0"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "sentiment_detect_model_v2 = MultinomialNB().fit(X_train2, y_train2)\n",
        "y_pred2 = sentiment_detect_model_v2.predict(X_test2)\n",
        "\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
        "accuracy_v2 = accuracy_score(y_test2, y_pred2)\n",
        "f1_v2 = f1_score(y_test2, y_pred2)\n",
        "conf_v2 = confusion_matrix(y_test2, y_pred2)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLd1I6MknccY",
        "outputId": "50e2f95a-5c72-4fa5-9c9d-6254553fc552"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "classificationr2=classification_report(y_test2, y_pred2)\n",
        "print(classificationr2)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.96      0.95      5945\n",
            "           1       0.96      0.93      0.95      5944\n",
            "\n",
            "    accuracy                           0.95     11889\n",
            "   macro avg       0.95      0.95      0.95     11889\n",
            "weighted avg       0.95      0.95      0.95     11889\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3JWjNBNqlQc"
      },
      "source": [
        "SMOTE sampling seems to have a slightly higher accuracy and F1 score compared to random oversampling. With the results so far, it seems like choosing SMOTE oversampling is preferable over original or random oversampling."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5NmXfIqqvpK"
      },
      "source": [
        "def pred2(text):\n",
        "  m = re.sub('[^a-zA-Z]', ' ', text)\n",
        "  m = re.sub('user', '', m)\n",
        "  m = m.lower()\n",
        "  m = m.split()\n",
        "  m = [ps.stem(word) for word in m if not word in stopwords.words('english')]\n",
        "  m =' '.join(m)\n",
        "  k=[]\n",
        "  k.append(m)\n",
        "  x = cv.transform(k).toarray()\n",
        "  y_pred = sentiment_detect_model_v2.predict(x)\n",
        "  if y_pred[0]==0:\n",
        "    print(\"Positive\")\n",
        "  else:\n",
        "    print(\"Negative\")"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UYjJz-Axq2CQ",
        "outputId": "223e36f7-3037-4987-e1f1-00cd01cf0f83"
      },
      "source": [
        "text = \"I am disgusted by the way he acted\"\n",
        "pred2(text)\n",
        "text = \"The black man was murdered\"\n",
        "pred2(text)\n",
        "text = \"I am delighted at your arrival, i though I would never see you again!!\"\n",
        "pred2(text)\n",
        "text = \"The man was excited and elated for the dinner he had been planning for a long time\"\n",
        "pred2(text)\n",
        "text = \"I am happy for the concert, will get to go out after a long time\"\n",
        "pred2(text)\n",
        "text = \"Women cannot do what men can do\"\n",
        "pred2(text)\n",
        "text = \"The world is a beautiful place\"\n",
        "pred2(text)\n",
        "text = \"Whites are superior then the black\"\n",
        "pred2(text)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Negative\n",
            "Negative\n",
            "Positive\n",
            "Positive\n",
            "Positive\n",
            "Negative\n",
            "Positive\n",
            "Negative\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}